{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T19:19:38.668354Z",
     "start_time": "2019-10-22T19:19:35.607565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import datetime \n",
    "import pixiedust\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from proj1_helpers import *\n",
    "from functools import reduce\n",
    "from datetime import datetime\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T19:19:39.445939Z",
     "start_time": "2019-10-22T19:19:38.670286Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>...</th>\n",
       "      <th>PRI_met_phi</th>\n",
       "      <th>PRI_met_sumet</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>s</td>\n",
       "      <td>138.470</td>\n",
       "      <td>51.655</td>\n",
       "      <td>97.827</td>\n",
       "      <td>27.980</td>\n",
       "      <td>0.910</td>\n",
       "      <td>124.711</td>\n",
       "      <td>2.666</td>\n",
       "      <td>3.064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>258.733</td>\n",
       "      <td>2</td>\n",
       "      <td>67.435</td>\n",
       "      <td>2.150</td>\n",
       "      <td>0.444</td>\n",
       "      <td>46.062</td>\n",
       "      <td>1.240</td>\n",
       "      <td>-2.475</td>\n",
       "      <td>113.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>100001</td>\n",
       "      <td>b</td>\n",
       "      <td>160.937</td>\n",
       "      <td>68.768</td>\n",
       "      <td>103.235</td>\n",
       "      <td>48.146</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.473</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.916</td>\n",
       "      <td>164.546</td>\n",
       "      <td>1</td>\n",
       "      <td>46.226</td>\n",
       "      <td>0.725</td>\n",
       "      <td>1.158</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>46.226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>100002</td>\n",
       "      <td>b</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>162.172</td>\n",
       "      <td>125.953</td>\n",
       "      <td>35.635</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.148</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.186</td>\n",
       "      <td>260.414</td>\n",
       "      <td>1</td>\n",
       "      <td>44.251</td>\n",
       "      <td>2.053</td>\n",
       "      <td>-2.028</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>44.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>100003</td>\n",
       "      <td>b</td>\n",
       "      <td>143.905</td>\n",
       "      <td>81.417</td>\n",
       "      <td>80.943</td>\n",
       "      <td>0.414</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060</td>\n",
       "      <td>86.062</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>100004</td>\n",
       "      <td>b</td>\n",
       "      <td>175.864</td>\n",
       "      <td>16.915</td>\n",
       "      <td>134.805</td>\n",
       "      <td>16.405</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.891</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.871</td>\n",
       "      <td>53.131</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>100005</td>\n",
       "      <td>b</td>\n",
       "      <td>89.744</td>\n",
       "      <td>13.550</td>\n",
       "      <td>59.149</td>\n",
       "      <td>116.344</td>\n",
       "      <td>2.636</td>\n",
       "      <td>284.584</td>\n",
       "      <td>-0.540</td>\n",
       "      <td>1.362</td>\n",
       "      <td>...</td>\n",
       "      <td>2.237</td>\n",
       "      <td>282.849</td>\n",
       "      <td>3</td>\n",
       "      <td>90.547</td>\n",
       "      <td>-2.412</td>\n",
       "      <td>-0.653</td>\n",
       "      <td>56.165</td>\n",
       "      <td>0.224</td>\n",
       "      <td>3.106</td>\n",
       "      <td>193.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>100006</td>\n",
       "      <td>s</td>\n",
       "      <td>148.754</td>\n",
       "      <td>28.862</td>\n",
       "      <td>107.782</td>\n",
       "      <td>106.130</td>\n",
       "      <td>0.733</td>\n",
       "      <td>158.359</td>\n",
       "      <td>0.113</td>\n",
       "      <td>2.941</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.443</td>\n",
       "      <td>294.074</td>\n",
       "      <td>2</td>\n",
       "      <td>123.010</td>\n",
       "      <td>0.864</td>\n",
       "      <td>1.450</td>\n",
       "      <td>56.867</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-2.767</td>\n",
       "      <td>179.877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>100007</td>\n",
       "      <td>s</td>\n",
       "      <td>154.916</td>\n",
       "      <td>10.418</td>\n",
       "      <td>94.714</td>\n",
       "      <td>29.169</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.897</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.761</td>\n",
       "      <td>187.299</td>\n",
       "      <td>1</td>\n",
       "      <td>30.638</td>\n",
       "      <td>-0.715</td>\n",
       "      <td>-1.724</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>30.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>100008</td>\n",
       "      <td>b</td>\n",
       "      <td>105.594</td>\n",
       "      <td>50.559</td>\n",
       "      <td>100.989</td>\n",
       "      <td>4.288</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024</td>\n",
       "      <td>129.804</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>100009</td>\n",
       "      <td>s</td>\n",
       "      <td>128.053</td>\n",
       "      <td>88.941</td>\n",
       "      <td>69.272</td>\n",
       "      <td>193.392</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>1.609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.845</td>\n",
       "      <td>294.741</td>\n",
       "      <td>1</td>\n",
       "      <td>167.735</td>\n",
       "      <td>-2.767</td>\n",
       "      <td>-2.514</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>167.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>100010</td>\n",
       "      <td>b</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>86.240</td>\n",
       "      <td>79.692</td>\n",
       "      <td>27.201</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688</td>\n",
       "      <td>250.178</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>100011</td>\n",
       "      <td>b</td>\n",
       "      <td>114.744</td>\n",
       "      <td>10.286</td>\n",
       "      <td>75.712</td>\n",
       "      <td>30.816</td>\n",
       "      <td>2.563</td>\n",
       "      <td>252.599</td>\n",
       "      <td>-1.401</td>\n",
       "      <td>2.888</td>\n",
       "      <td>...</td>\n",
       "      <td>2.148</td>\n",
       "      <td>290.547</td>\n",
       "      <td>3</td>\n",
       "      <td>76.773</td>\n",
       "      <td>-0.790</td>\n",
       "      <td>0.303</td>\n",
       "      <td>56.876</td>\n",
       "      <td>1.773</td>\n",
       "      <td>-2.079</td>\n",
       "      <td>165.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>100012</td>\n",
       "      <td>b</td>\n",
       "      <td>145.297</td>\n",
       "      <td>64.234</td>\n",
       "      <td>103.565</td>\n",
       "      <td>106.999</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.183</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.907</td>\n",
       "      <td>232.362</td>\n",
       "      <td>1</td>\n",
       "      <td>93.117</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>1.943</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>93.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>100013</td>\n",
       "      <td>b</td>\n",
       "      <td>82.488</td>\n",
       "      <td>31.663</td>\n",
       "      <td>64.128</td>\n",
       "      <td>8.232</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.823</td>\n",
       "      <td>...</td>\n",
       "      <td>1.433</td>\n",
       "      <td>163.420</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>100014</td>\n",
       "      <td>b</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>109.412</td>\n",
       "      <td>14.398</td>\n",
       "      <td>17.323</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.472</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.583</td>\n",
       "      <td>198.616</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>100015</td>\n",
       "      <td>s</td>\n",
       "      <td>111.026</td>\n",
       "      <td>32.096</td>\n",
       "      <td>75.271</td>\n",
       "      <td>23.067</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.205</td>\n",
       "      <td>...</td>\n",
       "      <td>2.415</td>\n",
       "      <td>122.176</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>100016</td>\n",
       "      <td>b</td>\n",
       "      <td>114.256</td>\n",
       "      <td>4.351</td>\n",
       "      <td>67.963</td>\n",
       "      <td>47.221</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.954</td>\n",
       "      <td>...</td>\n",
       "      <td>2.055</td>\n",
       "      <td>191.568</td>\n",
       "      <td>1</td>\n",
       "      <td>36.263</td>\n",
       "      <td>-0.766</td>\n",
       "      <td>-0.686</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>36.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>100017</td>\n",
       "      <td>s</td>\n",
       "      <td>127.861</td>\n",
       "      <td>50.953</td>\n",
       "      <td>77.267</td>\n",
       "      <td>26.967</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.833</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.975</td>\n",
       "      <td>211.720</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>100018</td>\n",
       "      <td>b</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>85.186</td>\n",
       "      <td>68.827</td>\n",
       "      <td>5.042</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.116</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.033</td>\n",
       "      <td>151.816</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>100019</td>\n",
       "      <td>b</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>88.767</td>\n",
       "      <td>115.058</td>\n",
       "      <td>15.337</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.879</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.577</td>\n",
       "      <td>115.145</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>100020</td>\n",
       "      <td>b</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>89.705</td>\n",
       "      <td>41.765</td>\n",
       "      <td>18.437</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>1.395</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.169</td>\n",
       "      <td>225.139</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>100021</td>\n",
       "      <td>b</td>\n",
       "      <td>90.736</td>\n",
       "      <td>18.674</td>\n",
       "      <td>60.231</td>\n",
       "      <td>25.156</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645</td>\n",
       "      <td>169.061</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>100022</td>\n",
       "      <td>b</td>\n",
       "      <td>87.075</td>\n",
       "      <td>38.217</td>\n",
       "      <td>67.041</td>\n",
       "      <td>2.347</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.852</td>\n",
       "      <td>...</td>\n",
       "      <td>2.008</td>\n",
       "      <td>68.527</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>100023</td>\n",
       "      <td>s</td>\n",
       "      <td>141.481</td>\n",
       "      <td>0.736</td>\n",
       "      <td>111.581</td>\n",
       "      <td>174.075</td>\n",
       "      <td>1.955</td>\n",
       "      <td>364.344</td>\n",
       "      <td>-0.923</td>\n",
       "      <td>1.335</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.973</td>\n",
       "      <td>454.785</td>\n",
       "      <td>2</td>\n",
       "      <td>195.533</td>\n",
       "      <td>1.156</td>\n",
       "      <td>1.416</td>\n",
       "      <td>82.477</td>\n",
       "      <td>-0.798</td>\n",
       "      <td>-2.785</td>\n",
       "      <td>278.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>100024</td>\n",
       "      <td>b</td>\n",
       "      <td>110.785</td>\n",
       "      <td>72.927</td>\n",
       "      <td>82.775</td>\n",
       "      <td>30.888</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.032</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>253.577</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>100025</td>\n",
       "      <td>b</td>\n",
       "      <td>76.883</td>\n",
       "      <td>34.384</td>\n",
       "      <td>56.993</td>\n",
       "      <td>5.569</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.912</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.397</td>\n",
       "      <td>93.086</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>100026</td>\n",
       "      <td>s</td>\n",
       "      <td>137.197</td>\n",
       "      <td>68.009</td>\n",
       "      <td>78.296</td>\n",
       "      <td>35.332</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.883</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.891</td>\n",
       "      <td>82.224</td>\n",
       "      <td>1</td>\n",
       "      <td>35.527</td>\n",
       "      <td>4.347</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>35.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>100027</td>\n",
       "      <td>s</td>\n",
       "      <td>111.271</td>\n",
       "      <td>27.180</td>\n",
       "      <td>70.642</td>\n",
       "      <td>144.766</td>\n",
       "      <td>4.936</td>\n",
       "      <td>1021.322</td>\n",
       "      <td>-5.834</td>\n",
       "      <td>1.795</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.173</td>\n",
       "      <td>289.876</td>\n",
       "      <td>2</td>\n",
       "      <td>170.712</td>\n",
       "      <td>-1.961</td>\n",
       "      <td>2.220</td>\n",
       "      <td>43.458</td>\n",
       "      <td>2.974</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>214.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>100028</td>\n",
       "      <td>s</td>\n",
       "      <td>118.104</td>\n",
       "      <td>2.633</td>\n",
       "      <td>77.310</td>\n",
       "      <td>91.388</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>1.976</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.127</td>\n",
       "      <td>175.843</td>\n",
       "      <td>1</td>\n",
       "      <td>77.221</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>1.426</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>77.221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>100029</td>\n",
       "      <td>b</td>\n",
       "      <td>98.761</td>\n",
       "      <td>14.024</td>\n",
       "      <td>74.230</td>\n",
       "      <td>132.806</td>\n",
       "      <td>3.676</td>\n",
       "      <td>315.854</td>\n",
       "      <td>-2.665</td>\n",
       "      <td>1.261</td>\n",
       "      <td>...</td>\n",
       "      <td>1.150</td>\n",
       "      <td>357.815</td>\n",
       "      <td>2</td>\n",
       "      <td>80.627</td>\n",
       "      <td>0.993</td>\n",
       "      <td>-2.018</td>\n",
       "      <td>32.625</td>\n",
       "      <td>-2.683</td>\n",
       "      <td>-1.467</td>\n",
       "      <td>113.252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id Prediction  DER_mass_MMC  DER_mass_transverse_met_lep  \\\n",
       "0   100000          s       138.470                       51.655   \n",
       "1   100001          b       160.937                       68.768   \n",
       "2   100002          b      -999.000                      162.172   \n",
       "3   100003          b       143.905                       81.417   \n",
       "4   100004          b       175.864                       16.915   \n",
       "5   100005          b        89.744                       13.550   \n",
       "6   100006          s       148.754                       28.862   \n",
       "7   100007          s       154.916                       10.418   \n",
       "8   100008          b       105.594                       50.559   \n",
       "9   100009          s       128.053                       88.941   \n",
       "10  100010          b      -999.000                       86.240   \n",
       "11  100011          b       114.744                       10.286   \n",
       "12  100012          b       145.297                       64.234   \n",
       "13  100013          b        82.488                       31.663   \n",
       "14  100014          b      -999.000                      109.412   \n",
       "15  100015          s       111.026                       32.096   \n",
       "16  100016          b       114.256                        4.351   \n",
       "17  100017          s       127.861                       50.953   \n",
       "18  100018          b      -999.000                       85.186   \n",
       "19  100019          b      -999.000                       88.767   \n",
       "20  100020          b      -999.000                       89.705   \n",
       "21  100021          b        90.736                       18.674   \n",
       "22  100022          b        87.075                       38.217   \n",
       "23  100023          s       141.481                        0.736   \n",
       "24  100024          b       110.785                       72.927   \n",
       "25  100025          b        76.883                       34.384   \n",
       "26  100026          s       137.197                       68.009   \n",
       "27  100027          s       111.271                       27.180   \n",
       "28  100028          s       118.104                        2.633   \n",
       "29  100029          b        98.761                       14.024   \n",
       "\n",
       "    DER_mass_vis  DER_pt_h  DER_deltaeta_jet_jet  DER_mass_jet_jet  \\\n",
       "0         97.827    27.980                 0.910           124.711   \n",
       "1        103.235    48.146              -999.000          -999.000   \n",
       "2        125.953    35.635              -999.000          -999.000   \n",
       "3         80.943     0.414              -999.000          -999.000   \n",
       "4        134.805    16.405              -999.000          -999.000   \n",
       "5         59.149   116.344                 2.636           284.584   \n",
       "6        107.782   106.130                 0.733           158.359   \n",
       "7         94.714    29.169              -999.000          -999.000   \n",
       "8        100.989     4.288              -999.000          -999.000   \n",
       "9         69.272   193.392              -999.000          -999.000   \n",
       "10        79.692    27.201              -999.000          -999.000   \n",
       "11        75.712    30.816                 2.563           252.599   \n",
       "12       103.565   106.999              -999.000          -999.000   \n",
       "13        64.128     8.232              -999.000          -999.000   \n",
       "14        14.398    17.323              -999.000          -999.000   \n",
       "15        75.271    23.067              -999.000          -999.000   \n",
       "16        67.963    47.221              -999.000          -999.000   \n",
       "17        77.267    26.967              -999.000          -999.000   \n",
       "18        68.827     5.042              -999.000          -999.000   \n",
       "19       115.058    15.337              -999.000          -999.000   \n",
       "20        41.765    18.437              -999.000          -999.000   \n",
       "21        60.231    25.156              -999.000          -999.000   \n",
       "22        67.041     2.347              -999.000          -999.000   \n",
       "23       111.581   174.075                 1.955           364.344   \n",
       "24        82.775    30.888              -999.000          -999.000   \n",
       "25        56.993     5.569              -999.000          -999.000   \n",
       "26        78.296    35.332              -999.000          -999.000   \n",
       "27        70.642   144.766                 4.936          1021.322   \n",
       "28        77.310    91.388              -999.000          -999.000   \n",
       "29        74.230   132.806                 3.676           315.854   \n",
       "\n",
       "    DER_prodeta_jet_jet  DER_deltar_tau_lep  ...  PRI_met_phi  PRI_met_sumet  \\\n",
       "0                 2.666               3.064  ...       -0.277        258.733   \n",
       "1              -999.000               3.473  ...       -1.916        164.546   \n",
       "2              -999.000               3.148  ...       -2.186        260.414   \n",
       "3              -999.000               3.310  ...        0.060         86.062   \n",
       "4              -999.000               3.891  ...       -0.871         53.131   \n",
       "5                -0.540               1.362  ...        2.237        282.849   \n",
       "6                 0.113               2.941  ...       -1.443        294.074   \n",
       "7              -999.000               2.897  ...       -1.761        187.299   \n",
       "8              -999.000               2.904  ...        0.024        129.804   \n",
       "9              -999.000               1.609  ...        0.845        294.741   \n",
       "10             -999.000               2.338  ...        0.688        250.178   \n",
       "11               -1.401               2.888  ...        2.148        290.547   \n",
       "12             -999.000               2.183  ...       -1.907        232.362   \n",
       "13             -999.000               2.823  ...        1.433        163.420   \n",
       "14             -999.000               0.472  ...       -1.583        198.616   \n",
       "15             -999.000               3.205  ...        2.415        122.176   \n",
       "16             -999.000               2.954  ...        2.055        191.568   \n",
       "17             -999.000               2.833  ...       -2.975        211.720   \n",
       "18             -999.000               2.116  ...       -2.033        151.816   \n",
       "19             -999.000               2.879  ...       -2.577        115.145   \n",
       "20             -999.000               1.395  ...       -1.169        225.139   \n",
       "21             -999.000               2.363  ...        0.645        169.061   \n",
       "22             -999.000               2.852  ...        2.008         68.527   \n",
       "23               -0.923               1.335  ...       -0.973        454.785   \n",
       "24             -999.000               3.032  ...       -0.716        253.577   \n",
       "25             -999.000               2.912  ...       -1.397         93.086   \n",
       "26             -999.000               2.883  ...       -2.891         82.224   \n",
       "27               -5.834               1.795  ...       -1.173        289.876   \n",
       "28             -999.000               1.976  ...       -1.127        175.843   \n",
       "29               -2.665               1.261  ...        1.150        357.815   \n",
       "\n",
       "    PRI_jet_num  PRI_jet_leading_pt  PRI_jet_leading_eta  PRI_jet_leading_phi  \\\n",
       "0             2              67.435                2.150                0.444   \n",
       "1             1              46.226                0.725                1.158   \n",
       "2             1              44.251                2.053               -2.028   \n",
       "3             0            -999.000             -999.000             -999.000   \n",
       "4             0            -999.000             -999.000             -999.000   \n",
       "5             3              90.547               -2.412               -0.653   \n",
       "6             2             123.010                0.864                1.450   \n",
       "7             1              30.638               -0.715               -1.724   \n",
       "8             0            -999.000             -999.000             -999.000   \n",
       "9             1             167.735               -2.767               -2.514   \n",
       "10            0            -999.000             -999.000             -999.000   \n",
       "11            3              76.773               -0.790                0.303   \n",
       "12            1              93.117               -0.970                1.943   \n",
       "13            0            -999.000             -999.000             -999.000   \n",
       "14            0            -999.000             -999.000             -999.000   \n",
       "15            0            -999.000             -999.000             -999.000   \n",
       "16            1              36.263               -0.766               -0.686   \n",
       "17            0            -999.000             -999.000             -999.000   \n",
       "18            0            -999.000             -999.000             -999.000   \n",
       "19            0            -999.000             -999.000             -999.000   \n",
       "20            0            -999.000             -999.000             -999.000   \n",
       "21            0            -999.000             -999.000             -999.000   \n",
       "22            0            -999.000             -999.000             -999.000   \n",
       "23            2             195.533                1.156                1.416   \n",
       "24            0            -999.000             -999.000             -999.000   \n",
       "25            0            -999.000             -999.000             -999.000   \n",
       "26            1              35.527                4.347               -0.169   \n",
       "27            2             170.712               -1.961                2.220   \n",
       "28            1              77.221               -0.049                1.426   \n",
       "29            2              80.627                0.993               -2.018   \n",
       "\n",
       "    PRI_jet_subleading_pt  PRI_jet_subleading_eta  PRI_jet_subleading_phi  \\\n",
       "0                  46.062                   1.240                  -2.475   \n",
       "1                -999.000                -999.000                -999.000   \n",
       "2                -999.000                -999.000                -999.000   \n",
       "3                -999.000                -999.000                -999.000   \n",
       "4                -999.000                -999.000                -999.000   \n",
       "5                  56.165                   0.224                   3.106   \n",
       "6                  56.867                   0.131                  -2.767   \n",
       "7                -999.000                -999.000                -999.000   \n",
       "8                -999.000                -999.000                -999.000   \n",
       "9                -999.000                -999.000                -999.000   \n",
       "10               -999.000                -999.000                -999.000   \n",
       "11                 56.876                   1.773                  -2.079   \n",
       "12               -999.000                -999.000                -999.000   \n",
       "13               -999.000                -999.000                -999.000   \n",
       "14               -999.000                -999.000                -999.000   \n",
       "15               -999.000                -999.000                -999.000   \n",
       "16               -999.000                -999.000                -999.000   \n",
       "17               -999.000                -999.000                -999.000   \n",
       "18               -999.000                -999.000                -999.000   \n",
       "19               -999.000                -999.000                -999.000   \n",
       "20               -999.000                -999.000                -999.000   \n",
       "21               -999.000                -999.000                -999.000   \n",
       "22               -999.000                -999.000                -999.000   \n",
       "23                 82.477                  -0.798                  -2.785   \n",
       "24               -999.000                -999.000                -999.000   \n",
       "25               -999.000                -999.000                -999.000   \n",
       "26               -999.000                -999.000                -999.000   \n",
       "27                 43.458                   2.974                  -0.103   \n",
       "28               -999.000                -999.000                -999.000   \n",
       "29                 32.625                  -2.683                  -1.467   \n",
       "\n",
       "    PRI_jet_all_pt  \n",
       "0          113.497  \n",
       "1           46.226  \n",
       "2           44.251  \n",
       "3            0.000  \n",
       "4            0.000  \n",
       "5          193.660  \n",
       "6          179.877  \n",
       "7           30.638  \n",
       "8            0.000  \n",
       "9          167.735  \n",
       "10           0.000  \n",
       "11         165.640  \n",
       "12          93.117  \n",
       "13           0.000  \n",
       "14           0.000  \n",
       "15           0.000  \n",
       "16          36.263  \n",
       "17           0.000  \n",
       "18           0.000  \n",
       "19           0.000  \n",
       "20           0.000  \n",
       "21           0.000  \n",
       "22           0.000  \n",
       "23         278.009  \n",
       "24           0.000  \n",
       "25           0.000  \n",
       "26          35.527  \n",
       "27         214.170  \n",
       "28          77.221  \n",
       "29         113.252  \n",
       "\n",
       "[30 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw=pd.read_csv('../data/train.csv',sep=',')\n",
    "raw.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T19:19:45.761169Z",
     "start_time": "2019-10-22T19:19:39.448238Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'DER_mass_MMC' b'DER_mass_transverse_' b'DER_mass_vis' b'DER_pt_h'\n",
      " b'DER_deltaeta_jet_jet' b'DER_mass_jet_jet' b'DER_prodeta_jet_jet'\n",
      " b'DER_deltar_tau_lep' b'DER_pt_tot' b'DER_sum_pt' b'DER_pt_ratio_lep_tau'\n",
      " b'DER_met_phi_centrali' b'DER_lep_eta_centrali' b'PRI_tau_pt'\n",
      " b'PRI_tau_eta' b'PRI_tau_phi' b'PRI_lep_pt' b'PRI_lep_eta' b'PRI_lep_phi'\n",
      " b'PRI_met' b'PRI_met_phi' b'PRI_met_sumet' b'PRI_jet_num'\n",
      " b'PRI_jet_leading_pt' b'PRI_jet_leading_eta' b'PRI_jet_leading_phi'\n",
      " b'PRI_jet_subleading_p' b'PRI_jet_subleading_e' b'PRI_jet_subleading_p']\n"
     ]
    }
   ],
   "source": [
    "from proj1_helpers import *\n",
    "# TODO: download train data and supply path here\n",
    "DATA_TRAIN_PATH = '../data/train.csv'\n",
    "feature_label=np.genfromtxt('../data/train.csv', delimiter=',',dtype='S20',max_rows=1)[2:-1]\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "# tX.shape=(250000, 30): 250000个样本，每个样本有30个互相正交潜在特征\n",
    "# y.shape=(250000,): 250000个样本的对应模式，分别为1或者-1，1对应p,-1对应b\n",
    "# ids.shape=(250000,)\n",
    "# N = tX.shape[1]=30 ,feature 的数目\n",
    "print(feature_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T19:19:45.815653Z",
     "start_time": "2019-10-22T19:19:45.762730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b'DER_mass_MMC', 0.152456)\n",
      "(b'DER_mass_transverse_', 0.0)\n",
      "(b'DER_mass_vis', 0.0)\n",
      "(b'DER_pt_h', 0.0)\n",
      "(b'DER_deltaeta_jet_jet', 0.709828)\n",
      "(b'DER_mass_jet_jet', 0.709828)\n",
      "(b'DER_prodeta_jet_jet', 0.709828)\n",
      "(b'DER_deltar_tau_lep', 0.0)\n",
      "(b'DER_pt_tot', 0.0)\n",
      "(b'DER_sum_pt', 0.0)\n",
      "(b'DER_pt_ratio_lep_tau', 0.0)\n",
      "(b'DER_met_phi_centrali', 0.0)\n",
      "(b'DER_lep_eta_centrali', 0.709828)\n",
      "(b'PRI_tau_pt', 0.0)\n",
      "(b'PRI_tau_eta', 0.0)\n",
      "(b'PRI_tau_phi', 0.0)\n",
      "(b'PRI_lep_pt', 0.0)\n",
      "(b'PRI_lep_eta', 0.0)\n",
      "(b'PRI_lep_phi', 0.0)\n",
      "(b'PRI_met', 0.0)\n",
      "(b'PRI_met_phi', 0.0)\n",
      "(b'PRI_met_sumet', 0.0)\n",
      "(b'PRI_jet_num', 0.0)\n",
      "(b'PRI_jet_leading_pt', 0.399652)\n",
      "(b'PRI_jet_leading_eta', 0.399652)\n",
      "(b'PRI_jet_leading_phi', 0.399652)\n",
      "(b'PRI_jet_subleading_p', 0.709828)\n",
      "(b'PRI_jet_subleading_e', 0.709828)\n",
      "(b'PRI_jet_subleading_p', 0.709828)\n"
     ]
    }
   ],
   "source": [
    "#data check\n",
    "outlier_perc=(tX==-999.).sum(axis=0)/len(y)\n",
    "print('\\n'.join([str(element) for element in list(zip(feature_label,outlier_perc))]))\n",
    "#(b'DER_deltaeta_jet_jet', 0.709828)\n",
    "# (b'DER_mass_jet_jet', 0.709828)\n",
    "# (b'DER_prodeta_jet_jet', 0.709828)\n",
    "# (b'DER_lep_eta_centrali', 0.709828)\n",
    "# (b'PRI_jet_subleading_p', 0.709828)\n",
    "# (b'PRI_jet_subleading_e', 0.709828)\n",
    "# (b'PRI_jet_subleading_p', 0.709828)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T11:47:48.942310Z",
     "start_time": "2019-10-22T11:47:48.812523Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T19:19:46.119199Z",
     "start_time": "2019-10-22T19:19:45.817378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of tx before whitening: (250000, 30)\n",
      "number of implicite outiler features is 172958 \n",
      "shape of tx after whitening: (250000, 23)\n"
     ]
    }
   ],
   "source": [
    "def data_whitening(tx):\n",
    "    print(\"shape of tx before whitening:\",tx.shape)\n",
    "    tx=tx.copy()[:,outlier_perc<0.7]\n",
    "    num_cleaned=0\n",
    "    for col in tx.T:   # here 30 cols\n",
    "        q1=np.percentile(col,25)\n",
    "        q3=np.percentile(col,75)\n",
    "        interq = q3-q1\n",
    "        col_cleaned = col[col!=-999]\n",
    "        col_cleaned = col[col<=q3+interq*1.5]\n",
    "        col_cleaned = col_cleaned[col_cleaned>=q1-interq*1.5]\n",
    "        \n",
    "        num_cleaned+=(len(col)-len(col_cleaned))\n",
    "        \n",
    "        mean = np.mean(col_cleaned)\n",
    "        col[col==-999] = mean\n",
    "        col[col>q3+interq*1.5] = mean\n",
    "        col[col<q1-interq*1.5] = mean\n",
    "        \n",
    "    print(\"number of implicite outiler features is {} \".format(num_cleaned))\n",
    "    print(\"shape of tx after whitening:\",tx.shape)\n",
    "    return tx\n",
    "        \n",
    "tX=data_whitening(tX)\n",
    "\n",
    "\n",
    "# number of implicite outiler features is 273037 after 1.5q: 172958\n",
    "# number of explicite outlier samples is 181886"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T19:19:46.150792Z",
     "start_time": "2019-10-22T19:19:46.120846Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_min_max(tX):\n",
    "    return (tX-tX.min(axis=0))/(tX.max(axis=0)-tX.min(axis=0))\n",
    "def normalize_z_score(tX):\n",
    "    return (tX-tX.mean(axis=0))/tX.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T19:19:46.205404Z",
     "start_time": "2019-10-22T19:19:46.152362Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data normalization:tX_nor1= Min-Max Normalization tX_nor2= z-Score Normalization(zero-mean Normalization)\n",
    "tX_nor=normalize_min_max(tX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T19:19:46.535952Z",
     "start_time": "2019-10-22T19:19:46.207285Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tX_aug=np.concatenate((tX_nor,tX_nor**2,tX_nor**3,tX_nor**4),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T19:19:46.566408Z",
     "start_time": "2019-10-22T19:19:46.537413Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tX_aug2=np.concatenate((tX_nor2,tX_nor2**2,tX_nor2**3,tX_nor2**4),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T19:19:46.596967Z",
     "start_time": "2019-10-22T19:19:46.567694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 92)\n"
     ]
    }
   ],
   "source": [
    "print(tX_aug.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T19:19:46.628878Z",
     "start_time": "2019-10-22T19:19:46.598216Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zeromean(tX):\n",
    "    mean=np.mean(tX,axis=0)\n",
    "    tX=tX-mean\n",
    "    return tX,mean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def PCA(tX,n):\n",
    "    tX,mean=zeromean(tX)\n",
    "    cov=np.cov(tX,rowvar=0)\n",
    "    eigvalues,eigvecs=np.linalg.eig(np.mat(cov))\n",
    "    n_eigvecs=eigvecs[:,eigvalues.argsort(axis=0)[-1:-(n+1):-1]]\n",
    "    lowDDataMat=tX@n_eigvecs\n",
    "    reconMat=(lowDDataMat*n_eigvecs.T)+mean\n",
    "    return lowDDataMat,reconMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T19:19:46.658230Z",
     "start_time": "2019-10-22T19:19:46.630229Z"
    },
    "collapsed": true,
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "#%%pixie_debugger\n",
    "\n",
    "#PCA(tX,60)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 交叉验证来确定脊回归的惩罚项的数值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T19:20:02.393041Z",
     "start_time": "2019-10-22T19:19:46.659551Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: download train data and supply path here\n",
    "DATA_TEST_PATH = '../data/test.csv'\n",
    "y_test, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "\n",
    "# y_test.shape=(568238,)\n",
    "#tX_test.shape=(568238, 30)\n",
    "#w.shape should be (30,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T19:20:03.918761Z",
     "start_time": "2019-10-22T19:20:02.396458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of tx before whitening: (568238, 30)\n",
      "number of implicite outiler features is 391756 \n",
      "shape of tx after whitening: (568238, 23)\n"
     ]
    }
   ],
   "source": [
    "tX_test=data_whitening(tX_test)\n",
    "tX_test_nor=normalize_min_max(tX_test)\n",
    "tX_test_aug=np.concatenate((tX_test_nor,tX_test_nor**2,tX_test_nor**3,tX_test_nor**4),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient_Descent  -2.2647  max_iters = 500  γ = 10**-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T19:20:03.961500Z",
     "start_time": "2019-10-22T19:20:03.920658Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#least squares GD(y, tx, initial w, max iters, gamma)\n",
    "def compute_loss_mse(y, tx, w):\n",
    "    e=y-tx@w     # e.shape shoulbe be (568238,)\n",
    "    N=y.shape[0]  #N shoulbe be the number of samples, so 568238\n",
    "    error=(1/2*N)*e@e\n",
    "    return error\n",
    "\n",
    "\n",
    "def compute_gradient(y, tx, w):\n",
    "    e=y-tx@w    # e.shape shoulbe be (568238,)\n",
    "    N=y.shape[0]  #N shoulbe be the number of samples, so 568238\n",
    "    gradient=(-1/N)*tx.T@e  #gradient.shape shoulbe be the number of dimension, so (30,)\n",
    "    return gradient\n",
    "\n",
    "\n",
    "def gradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    #y.shape=(568238,)   tX.shape=(568238, 30)  initial_w.shape=(30,)\n",
    "    \"\"\"Gradient descent algorithm.\"\"\"\n",
    "    ws = [initial_w]    #ws 会存有每次迭代的结果，总共max_iters个       \n",
    "    losses = []\n",
    "    w = initial_w    #w.shape=(30,)\n",
    "    for n_iter in range(max_iters):\n",
    "        gradient=compute_gradient(y,tx,w)\n",
    "        loss=compute_loss_mse(y,tx,w)\n",
    "        w+=(-gamma)*gradient\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\"Gradient Descent({bi}/{ti}): loss={l:.4e}, w0={w0:.4f}, w1={w1:.4f}\".format(\n",
    "             bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0],w1=w[1]))\n",
    "    weights=ws[-1]\n",
    "    return losses, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T19:20:03.999136Z",
     "start_time": "2019-10-22T19:20:03.963178Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''find the optimal step size for the gradient descent, accroding to maths '''\n",
    "\n",
    "def find_stepsize(tx):\n",
    "    H=tx.T@tx\n",
    "    w,v=np.linalg.eig(H)\n",
    "    lambda_=np.max(w)\n",
    "    return 1/lambda_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T19:20:21.609382Z",
     "start_time": "2019-10-22T19:20:17.069907Z"
    },
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/199): loss=3.1250e+10, w0=-0.0055, w1=-0.0072\n",
      "Gradient Descent(1/199): loss=2.9984e+10, w0=-0.0091, w1=-0.0134\n",
      "Gradient Descent(2/199): loss=2.9340e+10, w0=-0.0116, w1=-0.0189\n",
      "Gradient Descent(3/199): loss=2.8934e+10, w0=-0.0134, w1=-0.0239\n",
      "Gradient Descent(4/199): loss=2.8626e+10, w0=-0.0147, w1=-0.0286\n",
      "Gradient Descent(5/199): loss=2.8365e+10, w0=-0.0157, w1=-0.0331\n",
      "Gradient Descent(6/199): loss=2.8133e+10, w0=-0.0165, w1=-0.0374\n",
      "Gradient Descent(7/199): loss=2.7920e+10, w0=-0.0172, w1=-0.0416\n",
      "Gradient Descent(8/199): loss=2.7723e+10, w0=-0.0177, w1=-0.0457\n",
      "Gradient Descent(9/199): loss=2.7539e+10, w0=-0.0181, w1=-0.0496\n",
      "Gradient Descent(10/199): loss=2.7368e+10, w0=-0.0185, w1=-0.0535\n",
      "Gradient Descent(11/199): loss=2.7208e+10, w0=-0.0188, w1=-0.0572\n",
      "Gradient Descent(12/199): loss=2.7058e+10, w0=-0.0190, w1=-0.0609\n",
      "Gradient Descent(13/199): loss=2.6918e+10, w0=-0.0192, w1=-0.0645\n",
      "Gradient Descent(14/199): loss=2.6786e+10, w0=-0.0193, w1=-0.0680\n",
      "Gradient Descent(15/199): loss=2.6662e+10, w0=-0.0194, w1=-0.0715\n",
      "Gradient Descent(16/199): loss=2.6545e+10, w0=-0.0194, w1=-0.0749\n",
      "Gradient Descent(17/199): loss=2.6434e+10, w0=-0.0194, w1=-0.0783\n",
      "Gradient Descent(18/199): loss=2.6329e+10, w0=-0.0193, w1=-0.0815\n",
      "Gradient Descent(19/199): loss=2.6230e+10, w0=-0.0192, w1=-0.0847\n",
      "Gradient Descent(20/199): loss=2.6136e+10, w0=-0.0191, w1=-0.0879\n",
      "Gradient Descent(21/199): loss=2.6047e+10, w0=-0.0189, w1=-0.0910\n",
      "Gradient Descent(22/199): loss=2.5962e+10, w0=-0.0187, w1=-0.0941\n",
      "Gradient Descent(23/199): loss=2.5881e+10, w0=-0.0185, w1=-0.0971\n",
      "Gradient Descent(24/199): loss=2.5804e+10, w0=-0.0182, w1=-0.1001\n",
      "Gradient Descent(25/199): loss=2.5730e+10, w0=-0.0180, w1=-0.1030\n",
      "Gradient Descent(26/199): loss=2.5659e+10, w0=-0.0176, w1=-0.1058\n",
      "Gradient Descent(27/199): loss=2.5591e+10, w0=-0.0173, w1=-0.1087\n",
      "Gradient Descent(28/199): loss=2.5526e+10, w0=-0.0170, w1=-0.1115\n",
      "Gradient Descent(29/199): loss=2.5464e+10, w0=-0.0166, w1=-0.1142\n",
      "Gradient Descent(30/199): loss=2.5404e+10, w0=-0.0162, w1=-0.1169\n",
      "Gradient Descent(31/199): loss=2.5346e+10, w0=-0.0158, w1=-0.1196\n",
      "Gradient Descent(32/199): loss=2.5290e+10, w0=-0.0154, w1=-0.1222\n",
      "Gradient Descent(33/199): loss=2.5237e+10, w0=-0.0150, w1=-0.1249\n",
      "Gradient Descent(34/199): loss=2.5185e+10, w0=-0.0145, w1=-0.1274\n",
      "Gradient Descent(35/199): loss=2.5135e+10, w0=-0.0141, w1=-0.1300\n",
      "Gradient Descent(36/199): loss=2.5086e+10, w0=-0.0136, w1=-0.1325\n",
      "Gradient Descent(37/199): loss=2.5039e+10, w0=-0.0131, w1=-0.1350\n",
      "Gradient Descent(38/199): loss=2.4994e+10, w0=-0.0126, w1=-0.1374\n",
      "Gradient Descent(39/199): loss=2.4949e+10, w0=-0.0121, w1=-0.1399\n",
      "Gradient Descent(40/199): loss=2.4906e+10, w0=-0.0116, w1=-0.1423\n",
      "Gradient Descent(41/199): loss=2.4865e+10, w0=-0.0110, w1=-0.1446\n",
      "Gradient Descent(42/199): loss=2.4824e+10, w0=-0.0105, w1=-0.1470\n",
      "Gradient Descent(43/199): loss=2.4785e+10, w0=-0.0100, w1=-0.1493\n",
      "Gradient Descent(44/199): loss=2.4747e+10, w0=-0.0094, w1=-0.1516\n",
      "Gradient Descent(45/199): loss=2.4709e+10, w0=-0.0089, w1=-0.1539\n",
      "Gradient Descent(46/199): loss=2.4673e+10, w0=-0.0083, w1=-0.1561\n",
      "Gradient Descent(47/199): loss=2.4637e+10, w0=-0.0077, w1=-0.1584\n",
      "Gradient Descent(48/199): loss=2.4603e+10, w0=-0.0072, w1=-0.1606\n",
      "Gradient Descent(49/199): loss=2.4569e+10, w0=-0.0066, w1=-0.1628\n",
      "Gradient Descent(50/199): loss=2.4536e+10, w0=-0.0060, w1=-0.1650\n",
      "Gradient Descent(51/199): loss=2.4504e+10, w0=-0.0054, w1=-0.1671\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-81c73ef7f962>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mw_initial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtX_aug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"float64\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtX_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-024d8a73c2c7>\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(y, tx, initial_w, max_iters, gamma)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_w\u001b[0m    \u001b[0;31m#w.shape=(30,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mgradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss_mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-024d8a73c2c7>\u001b[0m in \u001b[0;36mcompute_gradient\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0me\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mw\u001b[0m    \u001b[0;31m# e.shape shoulbe be (568238,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m#N shoulbe be the number of samples, so 568238\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mgradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0me\u001b[0m  \u001b[0;31m#gradient.shape shoulbe be the number of dimension, so (30,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#%%pixie_debugger\n",
    "\n",
    "max_iters = 200\n",
    "gamma=100000*find_stepsize(tX_aug).real\n",
    "\n",
    "w_initial = np.zeros(tX_aug.shape[1],dtype=\"float64\")\n",
    "\n",
    "losses,weights = gradient_descent(y, tX_aug, w_initial, max_iters, gamma)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T19:20:21.611336Z",
     "start_time": "2019-10-22T19:20:17.312Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(weights)\n",
    "OUTPUT_PATH = 'output/Gradient_Descent.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test_aug)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic_Gradient_Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T19:20:44.091489Z",
     "start_time": "2019-10-22T19:20:44.057539Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute a stochastic gradient from just few examples n and their corresponding y_n labels.\"\"\"\n",
    "    y = list(batch_iter(y, tx, 10, num_batches=1, shuffle=True))[0][0]\n",
    "    tx = list(batch_iter(y, tx, 10, num_batches=1, shuffle=True))[0][1]\n",
    "    s = compute_gradient(y, tx, w)\n",
    "    return s\n",
    "\n",
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"Stochastic gradient descent algorithm.\"\"\"\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        gradient = compute_stoch_gradient(y, tx, w)\n",
    "        loss = compute_loss_mse(y, tx, w)\n",
    "        w = w+(-gamma)*gradient\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\"stochastic_gradient_descent({bi}/{ti}): loss={l:.4e}, w0={w0:.4f}, w1={w1:.4f}\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "    weights=ws[-1]\n",
    "    return losses, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T19:20:54.192520Z",
     "start_time": "2019-10-22T19:20:49.852781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stochastic_gradient_descent(0/99): loss=3.1250e+10, w0=-0.0000, w1=-0.0000\n",
      "stochastic_gradient_descent(1/99): loss=3.1244e+10, w0=-0.0000, w1=-0.0000\n",
      "stochastic_gradient_descent(2/99): loss=3.1243e+10, w0=-0.0001, w1=-0.0000\n",
      "stochastic_gradient_descent(3/99): loss=3.1235e+10, w0=-0.0001, w1=-0.0000\n",
      "stochastic_gradient_descent(4/99): loss=3.1226e+10, w0=-0.0001, w1=-0.0000\n",
      "stochastic_gradient_descent(5/99): loss=3.1227e+10, w0=-0.0002, w1=-0.0001\n",
      "stochastic_gradient_descent(6/99): loss=3.1217e+10, w0=-0.0002, w1=-0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-42bc19e6a9c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Start SGD.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0msgd_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstochastic_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtX_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-40995e27eb1b>\u001b[0m in \u001b[0;36mstochastic_gradient_descent\u001b[0;34m(y, tx, initial_w, batch_size, max_iters, gamma)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_stoch_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss_mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-40995e27eb1b>\u001b[0m in \u001b[0;36mcompute_stoch_gradient\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_stoch_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"Compute a stochastic gradient from just few examples n and their corresponding y_n labels.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AEPFL_S1/ML_course/projects/project1/scripts/proj1_helpers.py\u001b[0m in \u001b[0;36mbatch_iter\u001b[0;34m(y, tx, batch_size, num_batches, shuffle)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mshuffle_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mshuffled_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshuffle_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mshuffled_tx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshuffle_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mshuffled_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_iters = 100\n",
    "gamma =1e-4 #find_stepsize(tX)\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.zeros(tX_aug.shape[1])\n",
    "\n",
    "# Start SGD.\n",
    "\n",
    "sgd_losses, weights = stochastic_gradient_descent(y, tX_aug, w_initial, batch_size, max_iters, gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T19:20:28.932870Z",
     "start_time": "2019-10-22T19:20:28.893411Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-0d74f8209277>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 起始点的选取很重要，选择w_initial = np.zeros(30) 的loss 是1e-9，\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#而选择w_initial = np.zeros(30) 的loss 是1e-12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'weights' is not defined"
     ]
    }
   ],
   "source": [
    "# 起始点的选取很重要，选择w_initial = np.zeros(30) 的loss 是1e-9，\n",
    "#而选择w_initial = np.zeros(30) 的loss 是1e-12\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:50:01.030231Z",
     "start_time": "2019-10-22T18:49:59.638090Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "OUTPUT_PATH = 'output/SGD.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test_aug)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least_Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:50:01.140680Z",
     "start_time": "2019-10-22T18:50:01.031666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.14764540e-03 -9.27544917e-03  4.31386977e-03 -1.11351762e-03\n",
      " -1.32246128e-01 -3.04927633e-03  8.41377467e-05 -1.86875639e-01\n",
      "  9.93351587e-02  2.22603459e-03 -1.57719056e-03 -1.35299353e-03\n",
      "  7.74327153e-05 -5.81784981e-04  1.04020161e-03 -4.88826000e-04\n",
      "  4.82443152e-04 -1.63206724e-04 -1.19490685e-01 -4.89920273e-04\n",
      "  1.86091155e-04  6.04931885e-04  1.37890273e-03]\n"
     ]
    }
   ],
   "source": [
    "def least_squares(y, tx):\n",
    "    a = tx.T.dot(tx)\n",
    "    b = tx.T.dot(y)\n",
    "    return np.linalg.solve(a, b)\n",
    "\n",
    "print(least_squares(y, tX))\n",
    "\n",
    "weights=least_squares(y, tX_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:50:02.625980Z",
     "start_time": "2019-10-22T18:50:01.142475Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'output/Least_Square.csv' \n",
    "y_pred = predict_labels(weights, tX_test_aug)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ridge_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:50:02.658185Z",
     "start_time": "2019-10-22T18:50:02.627765Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    N=y.shape[0]\n",
    "    i_matrix=np.eye(tx.shape[1])\n",
    "    w_optimal=np.linalg.inv(tx.T@tx+lambda_*(2*N)*i_matrix)@tx.T@y\n",
    "    loss=compute_loss_mse(y,tx,w_optimal)\n",
    "    return loss,w_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:50:02.815842Z",
     "start_time": "2019-10-22T18:50:02.659542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18324815497.76081, array([-8.41390360e+00,  7.01951175e-01, -4.61027420e-01, -5.38383318e-01,\n",
      "        5.39907005e-01,  1.84632064e-01, -7.76533349e-01, -1.00997466e+00,\n",
      "        5.03465927e-02,  1.60117237e-01,  8.73578299e-01, -6.04720054e-02,\n",
      "        5.26969593e-01,  8.79785806e-01, -9.52974460e-02, -8.77595608e-01,\n",
      "        5.58556410e-02,  9.61273316e-01,  4.43580896e-01,  9.82938274e-01,\n",
      "       -5.79389018e-01,  4.32491371e-01,  1.21632159e+00,  2.08056148e+01,\n",
      "       -7.38237280e+00,  5.66009318e+00,  8.42293244e-01, -1.18927756e+00,\n",
      "       -1.31077107e+00,  1.67661078e+00,  6.34002079e-01, -1.27407287e+00,\n",
      "        1.16257967e+00, -1.81601262e+00,  4.03605057e-01, -2.03855448e+00,\n",
      "       -5.91869856e-01,  3.33897895e-01,  2.10917425e+00, -3.00895019e-01,\n",
      "       -1.12683420e+00,  1.01580081e-01, -4.69509171e-01, -9.22982925e-01,\n",
      "        2.12152297e-01, -1.22143832e+00, -9.90069145e+00,  7.64962058e+00,\n",
      "       -7.04029997e+00, -8.00971540e-01,  9.34751864e-01,  2.07733425e+00,\n",
      "       -1.82819776e+00,  5.98406711e-01,  2.54759884e+00, -2.12486816e+00,\n",
      "        1.87123108e+00, -7.38544700e-01,  2.54781185e+00, -5.13744211e-01,\n",
      "       -3.62258035e-01, -2.24338866e+00,  5.38723221e-01, -6.76717503e-01,\n",
      "       -1.91918489e-01, -4.49218031e-01, -3.98404090e-01,  6.83165018e-04,\n",
      "        6.63835839e-01, -3.87633937e+00, -1.06407131e+00,  1.40892663e+00,\n",
      "        3.96433582e-01, -8.98034409e-01, -9.85981241e-01,  7.57007604e-01,\n",
      "       -4.81013233e-01, -1.11375277e+00,  8.95672072e-01, -9.36042015e-01,\n",
      "        4.01361179e-01, -1.01092976e+00,  2.06473501e-01,  1.15045832e-01,\n",
      "        9.95653953e-01, -2.98359324e-01,  9.73069807e-01, -4.09416879e-01,\n",
      "       -3.26584098e-01,  9.65594371e-01, -2.02054870e-01, -3.25204866e-01]))\n"
     ]
    }
   ],
   "source": [
    "print(ridge_regression(y, tX_aug,1e-6))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:50:04.334801Z",
     "start_time": "2019-10-22T18:50:02.817920Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_,weights=ridge_regression(y, tX_aug,1e-6)\n",
    "OUTPUT_PATH = 'output/Ridge_Regression.csv' \n",
    "y_pred = predict_labels(weights, tX_test_aug)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## logistic_regression  10000， 3m34s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T18:33:45.401710Z",
     "start_time": "2019-10-20T18:30:14.569652Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:50:04.369188Z",
     "start_time": "2019-10-22T18:50:04.337363Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "    return 1.0 / (1 + np.exp(-t))\n",
    "\n",
    "def calculate_loss(y, tx, w):\n",
    "    \"\"\"compute the cost by negative log likelihood.\"\"\"\n",
    "    pred = sigmoid(tx@w)\n",
    "    loss = y.T.dot(np.log(pred)) + (1 - y).T.dot(np.log(1 - pred))\n",
    "    return np.squeeze(- loss)\n",
    "\n",
    "def calculate_gradient(y, tx, w):\n",
    "    \"\"\"compute the gradient of loss.\"\"\"\n",
    "    pred = sigmoid(tx.dot(w))\n",
    "    grad = tx.T.dot(pred - y)\n",
    "    return grad\n",
    "\n",
    "def LR_learning_by_gradient_descent(y, tx, w, gamma):\n",
    "    \"\"\"\n",
    "    Do one step of gradient descen using logistic regression.\n",
    "    Return the loss and the updated w.\n",
    "    \"\"\"\n",
    "    loss = calculate_loss(y, tx, w)\n",
    "    grad = calculate_gradient(y, tx, w)\n",
    "    w -= gamma * grad\n",
    "    return loss, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:50:04.400648Z",
     "start_time": "2019-10-22T18:50:04.371078Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def calculate_hessian(y, tx, w):\n",
    "    \"\"\"return the hessian of the loss function.\"\"\"\n",
    "    S = sigmoid(tx.dot(w))*(1-sigmoid(tx.dot(w)))\n",
    "    S = np.reshape(S, [len(S)])\n",
    "    return tx.T.dot(np.diag(S)).dot(tx)\n",
    "\n",
    "def logistic_regression(y, tx, w):\n",
    "    \"\"\"return the loss, gradient, and hessian.\"\"\"\n",
    "    loss = calculate_loss(y, tx, w)\n",
    "    gradient = calculate_gradient(y, tx, w)\n",
    "    hessian = calculate_hessian(y, tx, w)\n",
    "    return loss, gradient, hessian\n",
    "\n",
    "def LR_learning_by_newton_method(y, tx, w):\n",
    "    \"\"\"\n",
    "    Do one step on Newton's method.\n",
    "    return the loss and updated w.\n",
    "    \"\"\"\n",
    "    loss, gradient, hessian = logistic_regression(y, tx, w)\n",
    "    w -= np.linalg.solve(hessian, gradient)\n",
    "    return loss, w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T19:13:59.581296Z",
     "start_time": "2019-10-22T19:13:57.276650Z"
    },
    "collapsed": true,
    "hidden": true,
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "#%%pixie_debugger\n",
    "w=np.zeros(tX_aug.shape[1])  #initialize weight\n",
    "gamma=1e-6\n",
    "_,weights=LR_learning_by_gradient_descent(y, tX_aug,w,gamma)\n",
    "\n",
    "OUTPUT_PATH = 'output/LogisticRegression.csv' \n",
    "y_pred = predict_labels(weights, tX_test_aug)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## reg_logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:50:05.907292Z",
     "start_time": "2019-10-22T18:50:05.872224Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def penalized_logistic_regression(y, tx, w, lambda_):\n",
    "    \"\"\"return the loss and gradient.\"\"\"\n",
    "    loss = calculate_loss(y, tx, w) + lambda_ * np.squeeze(w.T.dot(w))\n",
    "    gradient = calculate_gradient(y, tx, w) + 2 * lambda_ * w\n",
    "    return loss, gradient\n",
    "\n",
    "def RLR_learning_by_gradient_descent(y, tx, w, gamma, lambda_):\n",
    "    \"\"\"\n",
    "    Do one step of gradient descent, using the penalized logistic regression.\n",
    "    Return the loss and updated w.\n",
    "    \"\"\"\n",
    "    loss, gradient = penalized_logistic_regression(y, tx, w, lambda_)\n",
    "    w -= gamma * gradient\n",
    "    return loss, w\n",
    "def RLR_learning_by_newton_method(y, tx, w, gamma, lambda_):\n",
    "    \"\"\"\n",
    "    Do one step of gradient descent, using the penalized logistic regression.\n",
    "    Return the loss and updated w.\n",
    "    \"\"\"\n",
    "    loss, gradient = penalized_logistic_regression(y, tx, w, lambda_)\n",
    "    w -= np.linalg.solve(hessian, gradient)\n",
    "    return loss, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:50:07.285890Z",
     "start_time": "2019-10-22T18:50:05.908462Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "w=np.zeros(tX_aug.shape[1])  #initialize weight\n",
    "gamma=1e-6\n",
    "lambda_=1e-3\n",
    "_,weights=RLR_learning_by_gradient_descent(y, tX_aug,w,gamma,lambda_)\n",
    "\n",
    "OUTPUT_PATH = 'output/reg_LogisticRegression.csv' \n",
    "y_pred = predict_labels(weights, tX_test_aug)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-19T14:54:48.534Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T19:23:22.077002Z",
     "start_time": "2019-10-22T19:23:21.918976Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval] for k in range(k_fold)]\n",
    "    return np.array(k_indices)\n",
    "\n",
    "def compute_mse(y, tx, w):\n",
    "    \"\"\"compute the loss by mse.\"\"\"\n",
    "    e = y - tx.dot(w)\n",
    "    mse = e@e / (2 * len(e))\n",
    "    return mse\n",
    "\n",
    "def cross_validation(y, x, k_indices, k, gamma,max_iters):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "    # get k'th subgroup in test, others in train\n",
    "    te_indice = k_indices[k]\n",
    "    tr_indice = k_indices[~(np.arange(k_indices.shape[0]) == k)]\n",
    "    tr_indice = tr_indice.reshape(-1)\n",
    "    y_te = y[te_indice]\n",
    "    y_tr = y[tr_indice]\n",
    "    x_te = x[te_indice]\n",
    "    x_tr = x[tr_indice]\n",
    "    # ridge regression\n",
    "    initial_w=np.zeros(tX_aug.shape[1])\n",
    "    _,weights = gradient_descent(y_tr, x_tr, initial_w, max_iters, gamma)\n",
    "    # calculate the accuracy for train and test data\n",
    "    accu_tr= (predict_labels(weights, x_tr)==y_tr).sum()/len(y_tr)\n",
    "    print((predict_labels(weights, x_tr)==y_tr).sum())\n",
    "    accu_te= (predict_labels(weights, x_te)==y_te).sum()/len(y_te)\n",
    "    print((predict_labels(weights, x_te)==y_te).sum())\n",
    "    print(accu_tr, accu_te)\n",
    "    return accu_tr, accu_te,weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T19:28:51.219732Z",
     "start_time": "2019-10-22T19:28:46.217580Z"
    },
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/9): loss=1.7578e+10, w0=-0.0274, w1=-0.0364\n",
      "Gradient Descent(1/9): loss=1.6707e+10, w0=-0.0089, w1=-0.0457\n",
      "Gradient Descent(2/9): loss=1.6133e+10, w0=-0.0317, w1=-0.0764\n",
      "Gradient Descent(3/9): loss=1.5736e+10, w0=-0.0101, w1=-0.0815\n",
      "Gradient Descent(4/9): loss=1.5446e+10, w0=-0.0304, w1=-0.1086\n",
      "Gradient Descent(5/9): loss=1.5222e+10, w0=-0.0072, w1=-0.1110\n",
      "Gradient Descent(6/9): loss=1.5043e+10, w0=-0.0262, w1=-0.1359\n",
      "Gradient Descent(7/9): loss=1.4893e+10, w0=-0.0023, w1=-0.1365\n",
      "Gradient Descent(8/9): loss=1.4765e+10, w0=-0.0206, w1=-0.1599\n",
      "Gradient Descent(9/9): loss=1.4654e+10, w0=0.0036, w1=-0.1594\n",
      "127552\n",
      "42571\n",
      "0.6802773333333333 0.681136\n",
      "Gradient Descent(0/9): loss=1.7578e+10, w0=-0.0271, w1=-0.0362\n",
      "Gradient Descent(1/9): loss=1.6701e+10, w0=-0.0090, w1=-0.0458\n",
      "Gradient Descent(2/9): loss=1.6123e+10, w0=-0.0315, w1=-0.0763\n",
      "Gradient Descent(3/9): loss=1.5723e+10, w0=-0.0102, w1=-0.0816\n",
      "Gradient Descent(4/9): loss=1.5431e+10, w0=-0.0303, w1=-0.1086\n",
      "Gradient Descent(5/9): loss=1.5206e+10, w0=-0.0074, w1=-0.1111\n",
      "Gradient Descent(6/9): loss=1.5025e+10, w0=-0.0261, w1=-0.1359\n",
      "Gradient Descent(7/9): loss=1.4875e+10, w0=-0.0025, w1=-0.1367\n",
      "Gradient Descent(8/9): loss=1.4747e+10, w0=-0.0205, w1=-0.1599\n",
      "Gradient Descent(9/9): loss=1.4635e+10, w0=0.0034, w1=-0.1595\n",
      "127824\n",
      "42236\n",
      "0.681728 0.675776\n",
      "Gradient Descent(0/9): loss=1.7578e+10, w0=-0.0274, w1=-0.0362\n",
      "Gradient Descent(1/9): loss=1.6725e+10, w0=-0.0088, w1=-0.0453\n",
      "Gradient Descent(2/9): loss=1.6165e+10, w0=-0.0318, w1=-0.0760\n",
      "Gradient Descent(3/9): loss=1.5779e+10, w0=-0.0099, w1=-0.0808\n",
      "Gradient Descent(4/9): loss=1.5498e+10, w0=-0.0307, w1=-0.1080\n",
      "Gradient Descent(5/9): loss=1.5283e+10, w0=-0.0070, w1=-0.1101\n",
      "Gradient Descent(6/9): loss=1.5112e+10, w0=-0.0266, w1=-0.1352\n",
      "Gradient Descent(7/9): loss=1.4970e+10, w0=-0.0021, w1=-0.1354\n",
      "Gradient Descent(8/9): loss=1.4851e+10, w0=-0.0212, w1=-0.1591\n",
      "Gradient Descent(9/9): loss=1.4747e+10, w0=0.0038, w1=-0.1580\n",
      "126970\n",
      "42600\n",
      "0.6771733333333333 0.6816\n",
      "Gradient Descent(0/9): loss=1.7578e+10, w0=-0.0273, w1=-0.0363\n",
      "Gradient Descent(1/9): loss=1.6718e+10, w0=-0.0087, w1=-0.0456\n",
      "Gradient Descent(2/9): loss=1.6154e+10, w0=-0.0316, w1=-0.0763\n",
      "Gradient Descent(3/9): loss=1.5767e+10, w0=-0.0097, w1=-0.0811\n",
      "Gradient Descent(4/9): loss=1.5486e+10, w0=-0.0304, w1=-0.1085\n",
      "Gradient Descent(5/9): loss=1.5272e+10, w0=-0.0067, w1=-0.1105\n",
      "Gradient Descent(6/9): loss=1.5101e+10, w0=-0.0263, w1=-0.1358\n",
      "Gradient Descent(7/9): loss=1.4961e+10, w0=-0.0016, w1=-0.1359\n",
      "Gradient Descent(8/9): loss=1.4843e+10, w0=-0.0208, w1=-0.1598\n",
      "Gradient Descent(9/9): loss=1.4740e+10, w0=0.0044, w1=-0.1586\n",
      "126992\n",
      "42428\n",
      "0.6772906666666667 0.678848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6791173333333334, 0.6793399999999999)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%pixie_debugger\n",
    "\n",
    "def cross_validation_demo(y,x,gamma,max_iters):\n",
    "    seed = 5\n",
    "    k_fold = 4\n",
    "    # split data in k fold\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    # define lists to store the loss of training data and test data\n",
    "    accu_tr_set = []\n",
    "    accu_te_set = []\n",
    "    # cross validation\n",
    "\n",
    "    for k in range(k_fold):\n",
    "        accu_tr, accu_te,_ = cross_validation(y, x, k_indices, k, gamma,max_iters)\n",
    "\n",
    "        accu_tr_set.append(accu_tr)\n",
    "        accu_te_set.append(accu_te)\n",
    "        \n",
    "    return np.mean(accu_tr_set), np.mean(accu_te_set)\n",
    "\n",
    "\n",
    "max_iters=10\n",
    "gamma=2*tX_aug.shape[0]*find_stepsize(tX_aug).real\n",
    "cross_validation_demo(y,tX_aug,gamma,max_iters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T17:52:30.206846Z",
     "start_time": "2019-10-21T17:52:30.168572Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-fold test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:50:09.689052Z",
     "start_time": "2019-10-22T18:50:09.636301Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss_rmse(y, tx, w):\n",
    "    e = y - tx@w\n",
    "    return np.sqrt(calculate_mse(e))\n",
    "\n",
    "def calculate_mse(e):\n",
    "    \"\"\"Calculate the mse for vector e.\"\"\"\n",
    "    return 1/2*np.mean(e**2)\n",
    "\n",
    "def split_data(y, x, ratio, seed):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(x)\n",
    "    np.random.shuffle(y)\n",
    "    N=len(y)\n",
    "    cutNumber=int(np.round(ratio*N))\n",
    "    train_data_x=x[:cutNumber]\n",
    "    train_data_y=y[:cutNumber]\n",
    "    test_data_x=x[cutNumber:]\n",
    "    test_data_y=y[cutNumber:]\n",
    "\n",
    "    return train_data_x,train_data_y,test_data_x,test_data_y\n",
    "\n",
    "def predict_labels(weights, data):\n",
    "    \"\"\"Generates class predictions given weights, and a test data matrix\"\"\"\n",
    "    y_pred = np.dot(data, weights)\n",
    "    y_pred[np.where(y_pred <= 0)] = -1\n",
    "    y_pred[np.where(y_pred > 0)] = 1\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "def accuracy_test_GD(y, x,initial_w, max_iters, gamma,ratio, seed):\n",
    "    train_data_x,train_data_y,test_data_x,test_data_y = split_data(y,x,ratio,seed)\n",
    "    _,weights=gradient_descent(train_data_y, train_data_x, initial_w, max_iters, gamma)\n",
    "    accu_tr= ((predict_labels(weights, train_data_x)==train_data_y)*1).sum()/len(train_data_y)\n",
    "    accu_te= ((predict_labels(weights, test_data_x)==test_data_y)*1).sum()/len(test_data_y)\n",
    "    rmse_tr=compute_loss_rmse(train_data_y,train_data_x,weights)\n",
    "    rmse_te=compute_loss_rmse(test_data_y,test_data_x,weights)\n",
    "    print(\"proportion={p}, Training accuracy={tr:.3f}, Testing accuracy={te:.3f}\".format(\n",
    "          p=ratio, tr=accu_tr, te=accu_te))\n",
    "    \n",
    "    \n",
    "def accuracy_test_SGD(y, x,initial_w, batch_size,max_iters,gamma,ratio, seed):\n",
    "    train_data_x,train_data_y,test_data_x,test_data_y = split_data(y,x,ratio,seed)\n",
    "    _,weights=stochastic_gradient_descent(train_data_y, train_data_x, initial_w, batch_size,max_iters,gamma)\n",
    "    accu_tr= ((predict_labels(weights, train_data_x)==train_data_y)*1).sum()/len(train_data_y)\n",
    "    accu_te= ((predict_labels(weights, test_data_x)==test_data_y)*1).sum()/len(test_data_y)\n",
    "    rmse_tr=compute_loss_rmse(train_data_y,train_data_x,weights)\n",
    "    rmse_te=compute_loss_rmse(test_data_y,test_data_x,weights)\n",
    "    print(\"proportion={p}, Training accuracy={tr:.3f}, Testing accuracy={te:.3f}\".format(\n",
    "          p=ratio, tr=accu_tr, te=accu_te))\n",
    "    \n",
    "\n",
    "def accuracy_least_square(y,x,ratio, seed):\n",
    "    train_data_x,train_data_y,test_data_x,test_data_y = split_data(y,x,ratio,seed)\n",
    "    weights=least_squares(train_data_y, train_data_x)\n",
    "    accu_tr= ((predict_labels(weights, train_data_x)==train_data_y)*1).sum()/len(train_data_y)\n",
    "    accu_te= ((predict_labels(weights, test_data_x)==test_data_y)*1).sum()/len(test_data_y)\n",
    "    rmse_tr=compute_loss_rmse(train_data_y,train_data_x,weights)\n",
    "    rmse_te=compute_loss_rmse(test_data_y,test_data_x,weights)\n",
    "    print(\"proportion={p}, Training accuracy={tr:.3f}, Testing accuracy={te:.3f}\".format(\n",
    "          p=ratio, tr=accu_tr, te=accu_te))\n",
    "\n",
    "def accuracy_ridge_regression(y,x,lambda_,ratio, seed):\n",
    "    train_data_x,train_data_y,test_data_x,test_data_y = split_data(y,x,ratio,seed)\n",
    "    _,weights=ridge_regression(train_data_y, train_data_x,lambda_)\n",
    "    accu_tr= ((predict_labels(weights, train_data_x)==train_data_y)*1).sum()/len(train_data_y)\n",
    "    accu_te= ((predict_labels(weights, test_data_x)==test_data_y)*1).sum()/len(test_data_y)\n",
    "    rmse_tr=compute_loss_rmse(train_data_y,train_data_x,weights)\n",
    "    rmse_te=compute_loss_rmse(test_data_y,test_data_x,weights)\n",
    "    print(\"proportion={p}, Training accuracy={tr:.3f}, Testing accuracy={te:.3f}\".format(\n",
    "          p=ratio, tr=accu_tr, te=accu_te))\n",
    "    \n",
    "def accuracy_logistic_regression(y,x,w,gamma,ratio, seed):\n",
    "    train_data_x,train_data_y,test_data_x,test_data_y = split_data(y,x,ratio,seed)\n",
    "    _,weights=LR_learning_by_gradient_descent(y,x, w, gamma)\n",
    "    accu_tr= ((predict_labels(weights, train_data_x)==train_data_y)*1).sum()/len(train_data_y)\n",
    "    accu_te= ((predict_labels(weights, test_data_x)==test_data_y)*1).sum()/len(test_data_y)\n",
    "    rmse_tr=compute_loss_rmse(train_data_y,train_data_x,weights)\n",
    "    rmse_te=compute_loss_rmse(test_data_y,test_data_x,weights)\n",
    "    print(\"proportion={p}, Training accuracy={tr:.3f}, Testing accuracy={te:.3f}\".format(\n",
    "          p=ratio, tr=accu_tr, te=accu_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:50:10.969287Z",
     "start_time": "2019-10-22T18:50:09.690924Z"
    },
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/9): loss=2.4890e+14, w0=4.4013, w1=3.6500\n",
      "Gradient Descent(1/9): loss=9.2329e+13, w0=2.7702, w1=2.7037\n",
      "Gradient Descent(2/9): loss=3.5814e+13, w0=1.7500, w1=2.0961\n",
      "Gradient Descent(3/9): loss=1.5302e+13, w0=1.0982, w1=1.6934\n",
      "Gradient Descent(4/9): loss=7.7569e+12, w0=0.6694, w1=1.4155\n",
      "Gradient Descent(5/9): loss=4.8903e+12, w0=0.3762, w1=1.2140\n",
      "Gradient Descent(6/9): loss=3.7201e+12, w0=0.1661, w1=1.0601\n",
      "Gradient Descent(7/9): loss=3.1726e+12, w0=0.0075, w1=0.9362\n",
      "Gradient Descent(8/9): loss=2.8604e+12, w0=-0.1186, w1=0.8318\n",
      "Gradient Descent(9/9): loss=2.6429e+12, w0=-0.2236, w1=0.7404\n",
      "proportion=0.7, Training accuracy=0.473, Testing accuracy=0.471\n"
     ]
    }
   ],
   "source": [
    "\n",
    "initial_w=10*np.random.rand(tX_aug.shape[1])#np.zeros(120) \n",
    "max_iters=10  #1000-2000次\n",
    "gamma=100000*find_stepsize(tX_aug).real\n",
    "ratio=0.7\n",
    "seed=3\n",
    "accuracy_test_GD(y,tX_aug, initial_w, max_iters, gamma,ratio, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:50:15.103994Z",
     "start_time": "2019-10-22T18:50:10.972598Z"
    },
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stochastic_gradient_descent(0/9): loss=1.8932e+14, w0=3.8871, w1=6.0009\n",
      "stochastic_gradient_descent(1/9): loss=1.4105e+14, w0=2.8478, w1=5.1753\n",
      "stochastic_gradient_descent(2/9): loss=1.0682e+14, w0=1.9849, w1=4.4893\n",
      "stochastic_gradient_descent(3/9): loss=8.2116e+13, w0=1.2810, w1=3.9259\n",
      "stochastic_gradient_descent(4/9): loss=6.4349e+13, w0=0.7111, w1=3.4714\n",
      "stochastic_gradient_descent(5/9): loss=5.1500e+13, w0=0.2383, w1=3.0901\n",
      "stochastic_gradient_descent(6/9): loss=4.1863e+13, w0=-0.1397, w1=2.7881\n",
      "stochastic_gradient_descent(7/9): loss=3.4915e+13, w0=-0.4596, w1=2.5316\n",
      "stochastic_gradient_descent(8/9): loss=2.9599e+13, w0=-0.7027, w1=2.3325\n",
      "stochastic_gradient_descent(9/9): loss=2.5759e+13, w0=-0.9192, w1=2.1524\n",
      "proportion=0.7, Training accuracy=0.359, Testing accuracy=0.359\n"
     ]
    }
   ],
   "source": [
    "#%%pixie_debugger\n",
    "initial_w=10*np.random.rand(tX_aug.shape[1])\n",
    "max_iters=10\n",
    "gamma=100000*find_stepsize(tX_aug).real\n",
    "batch_size=1\n",
    "ratio=0.7\n",
    "seed=1\n",
    "accuracy_test_SGD(y,tX_aug, initial_w,batch_size, max_iters,gamma,ratio,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:50:15.969247Z",
     "start_time": "2019-10-22T18:50:15.106214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportion=0.7, Training accuracy=0.656, Testing accuracy=0.659\n"
     ]
    }
   ],
   "source": [
    "ratio=0.7\n",
    "seed=1\n",
    "accuracy_least_square(y,tX_aug,ratio,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:50:17.729851Z",
     "start_time": "2019-10-22T18:50:15.971155Z"
    },
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportion=0.8, Training accuracy=0.657, Testing accuracy=0.657\n"
     ]
    }
   ],
   "source": [
    "#%%pixie_debugger\n",
    "ratio=0.8\n",
    "seed=1\n",
    "lambda_=10\n",
    "accuracy_ridge_regression(y, tX_aug, lambda_,ratio,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T18:50:18.492441Z",
     "start_time": "2019-10-22T18:50:17.731637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportion=0.9, Training accuracy=0.657, Testing accuracy=0.660\n"
     ]
    }
   ],
   "source": [
    "ratio=0.9\n",
    "seed=1\n",
    "gamma=10000\n",
    "initial_w=np.zeros(tX_aug.shape[1])\n",
    "accuracy_logistic_regression(y, tX_aug,initial_w,gamma,ratio,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
